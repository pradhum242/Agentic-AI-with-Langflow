{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c0cb93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Using cached charset_normalizer-3.4.2-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pradhum.thakur\\desktop\\langgraph\\.venv\\lib\\site-packages (from requests) (3.10)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pradhum.thakur\\desktop\\langgraph\\.venv\\lib\\site-packages (from requests) (2025.6.15)\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp313-cp313-win_amd64.whl (105 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Installing collected packages: urllib3, charset_normalizer, requests\n",
      "\n",
      "   ---------------------------------------- 0/3 [urllib3]\n",
      "   ---------------------------------------- 0/3 [urllib3]\n",
      "   ---------------------------------------- 0/3 [urllib3]\n",
      "   ---------------------------------------- 0/3 [urllib3]\n",
      "   ------------- -------------------------- 1/3 [charset_normalizer]\n",
      "   ------------- -------------------------- 1/3 [charset_normalizer]\n",
      "   -------------------------- ------------- 2/3 [requests]\n",
      "   -------------------------- ------------- 2/3 [requests]\n",
      "   ---------------------------------------- 3/3 [requests]\n",
      "\n",
      "Successfully installed charset_normalizer-3.4.2 requests-2.32.4 urllib3-2.5.0\n"
     ]
    }
   ],
   "source": [
    "# Function calling\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca00f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import inspect\n",
    "import json\n",
    "from typing import (\n",
    "    TypedDict, \n",
    "    List, Dict, Literal, \n",
    "    Callable, Optional, Any, \n",
    "    get_type_hints\n",
    ")\n",
    "from openai import OpenAI\n",
    "from openai.types.chat.chat_completion_message import ChatCompletionMessage\n",
    "from openai.types.chat.chat_completion_message_tool_call import ChatCompletionMessageToolCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f79a96dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openai.vocareum.com/v1\",\n",
    "    api_key=api_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21587354",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    def __init__(self):\n",
    "        self._messages: List[Dict[str, str]] = []\n",
    "    \n",
    "    def add_message(self, \n",
    "                    role: Literal['user', 'system', 'assistant', 'tool'], \n",
    "                    content: str,\n",
    "                    tool_calls: dict=dict(),        #dict = dict() sets a default empty dictionary orrrrrrrrrr u can use {}\n",
    "                    tool_call_id=None)-> None:\n",
    "\n",
    "        message = {\n",
    "            \"role\": role,\n",
    "            \"content\": content,\n",
    "            \"tool_calls\": tool_calls,\n",
    "        }\n",
    "\n",
    "        if role == \"tool\":\n",
    "            message = {\n",
    "                \"role\": role,\n",
    "                \"content\": content,\n",
    "                \"tool_call_id\": tool_call_id,\n",
    "            }\n",
    "\n",
    "        self._messages.append(message)\n",
    "\n",
    "    def get_messages(self) -> List[Dict[str, str]]:\n",
    "        return self._messages\n",
    "\n",
    "    def last_message(self) -> None:\n",
    "        if self._messages:\n",
    "            return self._messages[-1]\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        self._messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b209569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing user question and assistant generated message in the memory\n",
    "\n",
    "def chat_with_tools(user_question:str=None, memory:Memory=None, model:str=\"gpt-4o-mini\", temperature=0.0, tools=None)-> str:\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": user_question}]\n",
    "    if memory:\n",
    "        if user_question:\n",
    "            memory.add_message(role=\"user\", content=user_question)\n",
    "        messages = memory.get_messages()        \n",
    "\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model = model,\n",
    "        temperature = temperature,\n",
    "        messages = messages,\n",
    "        tools=tools,\n",
    "    )\n",
    "    \n",
    "    ai_message = str(response.choices[0].message.content)\n",
    "    tool_calls = response.choices[0].message.tool_calls\n",
    "    \n",
    "    if memory:\n",
    "        memory.add_message(role=\"assistant\", content=ai_message, tool_calls=tool_calls)\n",
    "    \n",
    "    return ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77ca4e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power(base:float, exponent:float):\n",
    "    \"\"\"Exponentatiation: base to the power of exponent\"\"\"\n",
    "    \n",
    "    return base ** exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca09f8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's used for tool/function calling in OpenAI's GPT API.\n",
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"power\",\n",
    "        \"description\": \"Exponentatiation: base to the power of exponent\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"base\": {\"type\": \"number\"},\n",
    "                \"exponent\": {\"type\": \"number\"}\n",
    "            },\n",
    "            \"required\": [\"base\", \"exponent\"],\n",
    "            \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "    }\n",
    "}]\n",
    "\n",
    "\n",
    "\n",
    "# Backend json File................................\n",
    "        # {\n",
    "        # \"role\": \"assistant\",\n",
    "        # \"tool_calls\": [\n",
    "        #     {\n",
    "        #     \"id\": \"call_abc123\",\n",
    "        #     \"type\": \"function\",\n",
    "        #     \"function\": {\n",
    "        #         \"name\": \"power\",\n",
    "        #         \"arguments\": \"{\\\"base\\\": 2, \\\"exponent\\\": -5}\"\n",
    "        #     }\n",
    "        #     }\n",
    "        # ]\n",
    "        # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cad487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ee29e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"base\":2,\"exponent\":-5}\n",
      "call_m9MtVoJ6mgZpRMqyBYoMzOMK\n"
     ]
    }
   ],
   "source": [
    "# Instantiate memory and start with the system prompt\n",
    "memory = Memory()\n",
    "memory.add_message(role=\"system\", content=\"You're a helpful assitant\")\n",
    "\n",
    "# Call the LLM with a question that needs a tool\n",
    "ai_message = chat_with_tools(\n",
    "    user_question=\"2 to the power of -5?\",\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "# args = memory.last_message()['tool_calls'][0].function.arguments\n",
    "# print(args)\n",
    "# #tool_call_id = json.loads(memory.last_message()['tool_calls'][0].id)\n",
    "# tool_call_id = memory.last_message()['tool_calls'][0].id\n",
    "# print(tool_call_id)\n",
    "\n",
    "# Get the arguments from the tool_calls object and call the actual defined function\n",
    "args = json.loads(memory.last_message()['tool_calls'][0].function.arguments)\n",
    "result = power(args[\"base\"], args[\"exponent\"])\n",
    "\n",
    "# Extract the tool_call_id and feed the LLM with the result from the function \n",
    "\n",
    "tool_call_id = memory.last_message()['tool_calls'][0].id\n",
    "memory.add_message(\n",
    "    role=\"tool\",\n",
    "    content=str(result), \n",
    "    tool_call_id=tool_call_id\n",
    ")\n",
    "\n",
    "ai_message = chat_with_tools(\n",
    "\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876a5d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': \"You're a helpful assitant\", 'tool_calls': {}},\n",
       " {'role': 'user', 'content': '2 to the power of -5?', 'tool_calls': {}},\n",
       " {'role': 'assistant',\n",
       "  'content': 'None',\n",
       "  'tool_calls': [ChatCompletionMessageToolCall(id='call_BdcLmiuO7OWiY0WnyJ07n9jr', function=Function(arguments='{\"base\":2,\"exponent\":-5}', name='power'), type='function')]},\n",
       " {'role': 'tool',\n",
       "  'content': '0.03125',\n",
       "  'tool_call_id': 'call_BdcLmiuO7OWiY0WnyJ07n9jr'},\n",
       " {'role': 'assistant',\n",
       "  'content': '2 to the power of -5 is equal to 0.03125.',\n",
       "  'tool_calls': None}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.get_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22206335",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool:\n",
    "    def __init__(self, func:Callable):\n",
    "        self.func = func\n",
    "        self.name = func.__name__\n",
    "        self.description = func.__doc__\n",
    "        self.argument_types_map = get_type_hints(func)\n",
    "        self.signature = inspect.signature(func)\n",
    "        self.arguments = [\n",
    "            {\n",
    "                \"name\": key, \n",
    "                \"type\": self._infer_json_schema_type(value),\n",
    "                \"required\": param.default == inspect.Parameter.empty\n",
    "            } \n",
    "            for key, value in self.argument_types_map.items()\n",
    "            if (param := self.signature.parameters.get(key))\n",
    "        ]\n",
    "\n",
    "    def dict(self):\n",
    "        return {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": self.name,\n",
    "                \"description\": self.description,\n",
    "                \"parallel_tool_calls\": False,\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        argument[\"name\"]: {\n",
    "                            \"type\": argument[\"type\"],\n",
    "                        }\n",
    "                        for argument in self.arguments\n",
    "                    },\n",
    "                    \"required\": [\n",
    "                        argument[\"name\"] \n",
    "                        for argument in self.arguments \n",
    "                        if argument[\"required\"]\n",
    "                    ],\n",
    "                    \"additionalProperties\": False,\n",
    "                },\n",
    "                \"strict\": True\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.func(*args, **kwargs)\n",
    "    \n",
    "    def _infer_json_schema_type(self, arg_type: Any) -> str:\n",
    "        if arg_type == bool:\n",
    "            return \"boolean\"\n",
    "        elif arg_type == int:\n",
    "            return \"integer\"\n",
    "        elif arg_type == float:\n",
    "            return \"number\"\n",
    "        elif arg_type == str:\n",
    "            return \"string\"\n",
    "        elif arg_type == list:\n",
    "            return \"array\"\n",
    "        elif arg_type == dict:\n",
    "            return \"object\"\n",
    "        elif arg_type is None:\n",
    "            return \"null\"\n",
    "        elif arg_type == datetime.date or arg_type == datetime.datetime:\n",
    "            return \"string\"  # JSON Schema treats dates as strings\n",
    "        else:\n",
    "            return \"string\"  # Default to string if type is unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daa0ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_tool = Tool(power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0f57f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'power',\n",
       "  'description': 'Exponentatiation: base to the power of exponent',\n",
       "  'parallel_tool_calls': False,\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'base': {'type': 'number'}, 'exponent': {'type': 'number'}},\n",
       "   'required': ['base', 'exponent'],\n",
       "   'additionalProperties': False},\n",
       "  'strict': True}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_tool.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcf4cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_tool(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1ebda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update the Agent class\n",
    "\n",
    "# You will modify the logic responsible for:\n",
    "\n",
    "    # Processing user input – The agent should record and manage conversation history.\n",
    "    # Generating a response – The agent will use a language model to create a reply based on previous messages.\n",
    "    # Identifying when tools are needed – If a tool is required to complete the request, the agent should detect this and trigger the appropriate function.\n",
    "    # Handling tool execution and responses – The agent should execute the tool, capture its output, and integrate the result into the conversation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfae47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\"A tool-calling AI Agent\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name:str = \"Agent\", \n",
    "        role:str = \"Personal Assistant\",\n",
    "        instructions:str = \"Help users with any question\",\n",
    "        model:str = \"gpt-4o-mini\",\n",
    "        temperature:float = 0.0,\n",
    "        tools:List[Tool] = [],\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.role = role\n",
    "        self.instructions = instructions\n",
    "        self.model = model\n",
    "        self.temperature = temperature\n",
    "        self.memory = Memory()\n",
    "        self.memory.add_message(\n",
    "            role=\"system\",\n",
    "            content=f\"You're an AI Agent, your role is {self.role}, \" \n",
    "                    f\"and you need to {self.instructions}\",\n",
    "        )\n",
    "\n",
    "        self.client = client\n",
    "\n",
    "        self.tools = tools\n",
    "        self.tool_map = {t.name:t for t in tools}\n",
    "        self.openai_tools = [t.dict() for t in self.tools] if self.tools else None\n",
    "\n",
    "    def invoke(self, user_message: str) -> str:\n",
    "        self.memory.add_message(\n",
    "            role=\"user\",\n",
    "            content=user_message,\n",
    "        )\n",
    "\n",
    "        ai_message = self._get_completion(\n",
    "            messages = self.memory.get_messages(),\n",
    "        )\n",
    "\n",
    "        tool_calls = ai_message.tool_calls\n",
    "        self.memory.add_message(\n",
    "            role=\"assistant\",\n",
    "            content=ai_message.content,\n",
    "            tool_calls=tool_calls,\n",
    "        )\n",
    "\n",
    "        if tool_calls:\n",
    "            self._call_tools(tool_calls)\n",
    "            \n",
    "        return self.memory.last_message()\n",
    "\n",
    "    def _call_tools(self, tool_calls:List[ChatCompletionMessageToolCall]):\n",
    "        for t in tool_calls:\n",
    "            tool_call_id = t.id\n",
    "            function_name = t.function.name\n",
    "            args = json.loads(t.function.arguments)\n",
    "            callable_tool = self.tool_map[function_name]\n",
    "            result = callable_tool(**args)\n",
    "            self.memory.add_message(\n",
    "                role=\"tool\", \n",
    "                content=str(result), \n",
    "                tool_call_id=tool_call_id\n",
    "            )\n",
    "\n",
    "        ai_message = self._get_completion(\n",
    "            messages = self.memory.get_messages(),\n",
    "        )\n",
    "\n",
    "        tool_calls = ai_message.tool_calls\n",
    "\n",
    "        self.memory.add_message(\n",
    "            role=\"assistant\",\n",
    "            content=ai_message.content,\n",
    "            tool_calls=tool_calls,\n",
    "        )\n",
    "\n",
    "        if tool_calls:\n",
    "            self._call_tools(tool_calls)\n",
    "\n",
    "\n",
    "    def _get_completion(self, messages:List[Dict])-> ChatCompletionMessage:\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            temperature=self.temperature,\n",
    "            messages=messages,\n",
    "            tools=self.openai_tools,\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e18f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build some agents and have fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b4e4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(\n",
    "    tools=[Tool(power)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbbc716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant', 'content': '10 + 5 equals 15.', 'tool_calls': None}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"What is 10 + 5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27074dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You're an AI Agent, your role is Personal Assistant, and you need to Help users with any question\",\n",
       "  'tool_calls': {}},\n",
       " {'role': 'user', 'content': 'What is 10 + 5?', 'tool_calls': {}},\n",
       " {'role': 'assistant', 'content': '10 + 5 equals 15.', 'tool_calls': None}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.memory.get_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44912d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.memory.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d155d581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.memory.get_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e697a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': '3 to the power of (2 to the power of 2) is 81.',\n",
       " 'tool_calls': None}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"What is 3 to the power of (2 to the power of 2)?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e442193a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'What is 3 to the power of (2 to the power of 2)?',\n",
       "  'tool_calls': {}},\n",
       " {'role': 'assistant',\n",
       "  'content': None,\n",
       "  'tool_calls': [ChatCompletionMessageToolCall(id='call_syuRuVri1qJOo7E94WILwQvz', function=Function(arguments='{\"base\": 2, \"exponent\": 2}', name='power'), type='function'),\n",
       "   ChatCompletionMessageToolCall(id='call_iCKqw9xMy7U1WLOmEajmpxWP', function=Function(arguments='{\"base\": 3, \"exponent\": 0}', name='power'), type='function')]},\n",
       " {'role': 'tool',\n",
       "  'content': '4',\n",
       "  'tool_call_id': 'call_syuRuVri1qJOo7E94WILwQvz'},\n",
       " {'role': 'tool',\n",
       "  'content': '1',\n",
       "  'tool_call_id': 'call_iCKqw9xMy7U1WLOmEajmpxWP'},\n",
       " {'role': 'assistant',\n",
       "  'content': None,\n",
       "  'tool_calls': [ChatCompletionMessageToolCall(id='call_37HTEVJN2SIbQ5y5yh4OLITp', function=Function(arguments='{\"base\":3,\"exponent\":4}', name='power'), type='function')]},\n",
       " {'role': 'tool',\n",
       "  'content': '81',\n",
       "  'tool_call_id': 'call_37HTEVJN2SIbQ5y5yh4OLITp'},\n",
       " {'role': 'assistant',\n",
       "  'content': '3 to the power of (2 to the power of 2) is 81.',\n",
       "  'tool_calls': None}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.memory.get_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cccd506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a38f241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b31ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5cba18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e385f981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d7e634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8103d5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dfa15d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938e949e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847690ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72218195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b37b5309",
   "metadata": {},
   "source": [
    "# Additional "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545fc38c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9008e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "| Term         | Direction | Appears in        |\n",
    "| ------------ | --------- | ----------------- |\n",
    "| `tools`      | You ➜ LLM | **Request** only  |  What tools/functions you give to the LLM            input\n",
    "| `tool_calls` | LLM ➜ You | **Response** only |  What tools the LLM decided to call                  output\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb68fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    ")\n",
    "\"\"\"\n",
    "#############################################\n",
    "# OpenAi Response for above code looks like #\n",
    "#############################################\n",
    "\"\"\"\n",
    "{\n",
    "  \"choices\": [\n",
    "    {\n",
    "      \"message\": {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Let's use a tool.\",\n",
    "        \"tool_calls\": [\n",
    "          {\n",
    "            \"id\": \"call_abc123\",\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "              \"name\": \"get_weather\",\n",
    "              \"arguments\": \"{\\\"location\\\": \\\"Delhi\\\"}\"\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3735177f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d06381c",
   "metadata": {},
   "source": [
    "## How Tool calling WOrks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2568a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmessages.append({\\n    \"role\": \"tool\",\\n    \"tool_call_id\": tool_call.id,\\n    \"content\": result  # The result of get_weather()\\n})\\n\\nresponse = client.chat.completions.create(\\n    model=\"gpt-4o\",\\n    messages=messages\\n)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ✅ STEP 1: Define Your Python Function\n",
    "\"\"\"   \n",
    "def get_weather(location: str) -> str:\n",
    "    #Returns the current weather of the given location.  \n",
    "    return f\"The weather in {location} is sunny 🌞\"                    \n",
    "\"\"\"\n",
    "\n",
    "#✅ STEP 2: Wrap It as a Tool (OpenAI format)\n",
    "\"\"\"\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Returns the current weather of the given location.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\"type\": \"string\"},\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ✅ STEP 3: Make API Call with Tools\n",
    "\"\"\" \n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What's the weather in Delhi?\"}\n",
    "    ],\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# ✅ STEP 4: Handle tool_calls from the Response\n",
    "\"\"\"\n",
    "tool_calls = response.choices[0].message.tool_calls\n",
    "\"\"\"\n",
    "##################################################\n",
    "# If tool calls exist, process them:\n",
    "##################################################\n",
    "\"\"\"\n",
    "for tool_call in tool_calls:\n",
    "    function_name = tool_call.function.name\n",
    "    arguments = json.loads(tool_call.function.arguments)\n",
    "    \n",
    "    # Call actual Python function\n",
    "    if function_name == \"get_weather\":\n",
    "        result = get_weather(**arguments)  # get_weather(location=\"Delhi\")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 🧠 BONUS: Sending tool response back to LLM (optional)\n",
    "\"\"\"\n",
    "messages.append({\n",
    "    \"role\": \"tool\",\n",
    "    \"tool_call_id\": tool_call.id,\n",
    "    \"content\": result  # The result of get_weather()\n",
    "})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622a0762",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "| Step                  | What You Do                                   |\n",
    "| --------------------- | --------------------------------------------- |\n",
    "| 1. Define Tool        | Write your Python function                    |\n",
    "| 2. Wrap Tool          | Convert to JSON tool format                   |\n",
    "| 3. Send API Call      | Pass `tools=[...]` to `.create()`             |\n",
    "| 4. Check `tool_calls` | Read `response.choices[0].message.tool_calls` |\n",
    "| 5. Run Tool           | Call the real Python function                 |\n",
    "| 6. Respond (Optional) | Send result back via `role=\"tool\"`            |\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
